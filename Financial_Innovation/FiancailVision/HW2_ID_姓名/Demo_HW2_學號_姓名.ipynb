{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 題目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use LSTM & CNN model to classify MNIST dataset with at least 90%\n",
    "2. Use LSTM & CNN model to classify customized candlestick pattern (at least 3 classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 執行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所有檔案: mnist_train_all.py、 candlestick_train_cnn.py、candlestick_train_lstm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Use LSTM & CNN model to classify MNIST\n",
    "* mnist_train_all.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes):\n",
    "    x_train = x_train.reshape(-1, n_step, n_input)\n",
    "    x_test = x_test.reshape(-1, n_step, n_input)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "def cnn_preprocess(x_train, x_test, y_train, y_test):\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "def lstm_model(n_input, n_step, n_hidden, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_hidden, batch_input_shape=(None, n_step, n_input), unroll=True))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def trainning(model, x_train, y_train, x_test, y_test, \n",
    "              learning_rate, training_iters, batch_size):\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size, epochs=training_iters,\n",
    "              verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "def print_confusion_result(x_train, x_test, y_train, y_test, model):\n",
    "    # get train & test predictions\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    \n",
    "    # get train & test true labels\n",
    "    train_label = y_train\n",
    "    test_label =  y_test\n",
    "    \n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(10))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(10))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)\n",
    "\n",
    "def mnist_lstm_main():\n",
    "    # training parameters\n",
    "    learning_rate = 0.001\n",
    "    training_iters = 1\n",
    "    batch_size = 128\n",
    "\n",
    "    # model parameters\n",
    "    n_input = 28\n",
    "    n_step = 28\n",
    "    n_hidden = 256\n",
    "    n_classes = 10\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test, y_train_o, y_test_o = lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes)\n",
    "\n",
    "    model = lstm_model(n_input, n_step, n_hidden, n_classes)\n",
    "    trainning(model, x_train, y_train_o, x_test, y_test_o, learning_rate, training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test_o, verbose=0)\n",
    "    print('LSTM test accuracy:', scores[1])\n",
    "    print_confusion_result(x_train, x_test, y_train, y_test, model)\n",
    "\n",
    "def mnist_cnn_main():\n",
    "    # training parameters\n",
    "    learning_rate = 0.001\n",
    "    training_iters = 1\n",
    "    batch_size = 64\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test, y_train_o, y_test_o = cnn_preprocess(x_train, x_test, y_train, y_test)\n",
    "\n",
    "    model = cnn_model()\n",
    "    trainning(model, x_train, y_train_o, x_test, y_test_o, learning_rate, training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test_o, verbose=0)\n",
    "    print('CNN test accuracy:', scores[1])\n",
    "    print_confusion_result(x_train, x_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 6s 0us/step\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 256)               291840    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 294,410\n",
      "Trainable params: 294,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.4194 - accuracy: 0.8610 - val_loss: 0.1429 - val_accuracy: 0.9548\n",
      "LSTM test accuracy: 0.954800009727478\n",
      "[[5766    1   28   22    4   13   23    1   30   35]\n",
      " [   2 6641   35    3    5    6    2   30   15    3]\n",
      " [  12   18 5752   61   14    5   10   64   18    4]\n",
      " [   2   30   71 5788    1   21    0  100   97   21]\n",
      " [  12   22   43    0 5461    7   48   27   29  193]\n",
      " [   6    7   14  122    7 5185    9    3   37   31]\n",
      " [  29   13   10    5   39  124 5675    0   19    4]\n",
      " [   4   10   48    4   10    1    0 6090    4   94]\n",
      " [  16   39   36   98   14  140    5   17 5458   28]\n",
      " [  14   18   16   38   55   13    6   60   85 5644]] \n",
      "\n",
      " [[ 959    0    1    1    1    4    5    1    2    6]\n",
      " [   0 1120    5    0    0    1    1    1    7    0]\n",
      " [   3    1  992   11    1    3    2   15    4    0]\n",
      " [   0    0   12  963    0    3    0   17   11    4]\n",
      " [   1    2    6    1  916    1   11    4    7   33]\n",
      " [   3    0    1   26    2  842    1    1   10    6]\n",
      " [   8    3    2    0   13   30  897    1    4    0]\n",
      " [   0    3   13    1    0    0    0  990    2   19]\n",
      " [   2    1    5   12    3   28    0    6  913    4]\n",
      " [   4    6    1    5    6    0    2    9   20  956]]\n"
     ]
    }
   ],
   "source": [
    "mnist_lstm_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 48)        38448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               307456    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 84)                21588     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 369,174\n",
      "Trainable params: 369,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.1362 - accuracy: 0.9576 - val_loss: 0.0452 - val_accuracy: 0.9857\n",
      "CNN test accuracy: 0.9857000112533569\n",
      "[[5837    1   10    2    1   17   25    0   19   11]\n",
      " [   0 6671   15    9    2    2    3   12   25    3]\n",
      " [   2    6 5908   12    0    0    0   13    9    8]\n",
      " [   0    0   17 6059    0   35    0    3   11    6]\n",
      " [   2   11   26    1 5650    4   18    5   16  109]\n",
      " [   2    0    2    8    0 5394    9    0    6    0]\n",
      " [   4    2    5    1    2   38 5858    0    7    1]\n",
      " [   0   10   22   19    1    6    0 6128   14   65]\n",
      " [   3    3   13   11    0   45    5    0 5757   14]\n",
      " [   6    1    2    7    5   30    1    9   15 5873]] \n",
      "\n",
      " [[ 969    0    0    0    0    2    4    0    4    1]\n",
      " [   0 1120    0    2    0    1    1    1   10    0]\n",
      " [   1    2 1026    0    0    0    0    2    1    0]\n",
      " [   0    0    3  996    0    9    0    0    2    0]\n",
      " [   0    0    6    1  949    0    0    1    2   23]\n",
      " [   1    0    1    2    0  887    1    0    0    0]\n",
      " [   1    2    1    0    1    4  949    0    0    0]\n",
      " [   0    2    5    6    0    1    0 1000    2   12]\n",
      " [   0    0    2    1    0    4    0    0  966    1]\n",
      " [   1    2    0    1    0    7    0    0    3  995]]\n"
     ]
    }
   ],
   "source": [
    "mnist_cnn_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use LSTM model to classify customized candlestick pattern\n",
    "* candlestick_train_lstm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def load_pkl(pkl_name):\n",
    "    # load data from data folder\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes):\n",
    "    x_train = x_train.reshape(-1, n_step, n_input)\n",
    "    x_test = x_test.reshape(-1, n_step, n_input)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "def lstm_model(n_input, n_step, n_hidden, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_hidden, batch_input_shape=(None, n_step, n_input), unroll=True))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "def train_lstm(model, x_train, y_train, x_test, y_test, \n",
    "        learning_rate, training_iters, batch_size):\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=adam,\n",
    "        loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "        batch_size=batch_size, epochs=training_iters,\n",
    "        verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "def print_result(data, x_train, x_test, model):\n",
    "    # get train & test pred-labels\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    # get train & test true-labels\n",
    "    train_label = data['train_label'][:, 0]\n",
    "    test_label = data['test_label'][:, 0]\n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(9))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(9))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)\n",
    "\n",
    "def mnist_lstm_main():\n",
    "    # training parameters\n",
    "    learning_rate = 0.001\n",
    "    training_iters = 10\n",
    "    batch_size = 128\n",
    "\n",
    "    # model parameters\n",
    "    n_input = 40\n",
    "    n_step = 10\n",
    "    n_hidden = 256\n",
    "    n_classes = 10\n",
    "\n",
    "    data = load_pkl('./data/label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl')\n",
    "    x_train, y_train, x_test, y_test = data['train_gaf'], data['train_label'][:, 0], data['test_gaf'], data['test_label'][:, 0]\n",
    "    x_train, x_test, y_train, y_test = lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes)\n",
    "\n",
    "    model = lstm_model(n_input, n_step, n_hidden, n_classes)\n",
    "    train_lstm(model, x_train, y_train, x_test, y_test, learning_rate, \n",
    "               training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('LSTM test accuracy:', scores[1])\n",
    "    print_result(data, x_train, x_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 256)               304128    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 306,698\n",
      "Trainable params: 306,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 17s 1ms/step - loss: 2.1169 - accuracy: 0.2050 - val_loss: 1.6761 - val_accuracy: 0.2472\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 11s 746us/step - loss: 1.4956 - accuracy: 0.3326 - val_loss: 1.3314 - val_accuracy: 0.4038\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 11s 746us/step - loss: 1.3239 - accuracy: 0.4039 - val_loss: 1.2824 - val_accuracy: 0.4360\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 11s 739us/step - loss: 1.2683 - accuracy: 0.4301 - val_loss: 1.2554 - val_accuracy: 0.4656\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 11s 746us/step - loss: 1.1582 - accuracy: 0.5188 - val_loss: 1.0180 - val_accuracy: 0.5980\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 11s 738us/step - loss: 0.7785 - accuracy: 0.6987 - val_loss: 0.8157 - val_accuracy: 0.6936\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 11s 735us/step - loss: 0.6602 - accuracy: 0.7441 - val_loss: 0.8767 - val_accuracy: 0.6538\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 11s 742us/step - loss: 0.6418 - accuracy: 0.7509 - val_loss: 0.5208 - val_accuracy: 0.8068\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 11s 732us/step - loss: 0.5982 - accuracy: 0.7694 - val_loss: 0.6588 - val_accuracy: 0.7532\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 11s 737us/step - loss: 0.5939 - accuracy: 0.7735 - val_loss: 0.5461 - val_accuracy: 0.7988\n",
      "LSTM test accuracy: 0.798799991607666\n",
      "[[1676  133  143  115  138  353  222  117  103]\n",
      " [  85 1354    0   57    0    4    0    0    0]\n",
      " [ 132    0 1315    0   53    0    0    0    0]\n",
      " [  50   31    0  965    0   13    0  441    0]\n",
      " [  37    0   38    0 1387    0    0    0   38]\n",
      " [  70    4    0    0    0 1414    0   12    0]\n",
      " [ 191    2    1    0   11    0 1148    0  147]\n",
      " [  30    3    0   67    0  148    0 1252    0]\n",
      " [  27    0    2    0  317    0    0    0 1154]] \n",
      "\n",
      " [[573  26  53  43  48 128  72  32  25]\n",
      " [ 19 458   0  22   0   1   0   0   0]\n",
      " [ 32   0 458   0  10   0   0   0   0]\n",
      " [ 11   5   0 322   0  13   0 149   0]\n",
      " [ 15   0  21   0 454   0   0   0  10]\n",
      " [ 21   0   0   0   0 479   0   0   0]\n",
      " [ 51   0   1   0   3   0 398   0  47]\n",
      " [  4   0   0   3   0  57   0 436   0]\n",
      " [  5   0   0   0  77   0   2   0 416]]\n"
     ]
    }
   ],
   "source": [
    "mnist_lstm_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Use CNN model to classify customized candlestick pattern\n",
    "* candlestick_train_cnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, Activation, MaxPool2D\n",
    "\n",
    "\n",
    "def load_pkl(pkl_name):\n",
    "    # load data from data folder\n",
    "    with open(pkl_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def get_cnn_model(params):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(10, 10, 4)))\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def train_model(params, data):\n",
    "    model = get_cnn_model(params)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=params['optimizer'], metrics=['accuracy'])\n",
    "    hist = model.fit(x=data['train_gaf'], y=data['train_label_arr'],\n",
    "                     batch_size=params['batch_size'], epochs=params['epochs'], verbose=2)\n",
    "    return (model, hist)\n",
    "\n",
    "def print_result(data, model):\n",
    "    # get train & test pred-labels\n",
    "    train_pred = model.predict_classes(data['train_gaf'])\n",
    "    test_pred = model.predict_classes(data['test_gaf'])\n",
    "    # get train & test true-labels\n",
    "    train_label = data['train_label'][:, 0]\n",
    "    test_label = data['test_label'][:, 0]\n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(9))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(9))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 7s - loss: 1.6107 - accuracy: 0.3959\n",
      "Epoch 2/10\n",
      " - 7s - loss: 0.8380 - accuracy: 0.6993\n",
      "Epoch 3/10\n",
      " - 7s - loss: 0.6212 - accuracy: 0.7775\n",
      "Epoch 4/10\n",
      " - 7s - loss: 0.5313 - accuracy: 0.8105\n",
      "Epoch 5/10\n",
      " - 7s - loss: 0.4924 - accuracy: 0.8224\n",
      "Epoch 6/10\n",
      " - 7s - loss: 0.4706 - accuracy: 0.8309\n",
      "Epoch 7/10\n",
      " - 7s - loss: 0.4450 - accuracy: 0.8418\n",
      "Epoch 8/10\n",
      " - 7s - loss: 0.4250 - accuracy: 0.8457\n",
      "Epoch 9/10\n",
      " - 7s - loss: 0.4073 - accuracy: 0.8531\n",
      "Epoch 10/10\n",
      " - 7s - loss: 0.3987 - accuracy: 0.8562\n",
      "CNN test accuracy: 0.8113999962806702\n",
      "[[2492   50   33   37   31  145   73   99   40]\n",
      " [  95 1403    0    2    0    0    0    0    0]\n",
      " [ 340    0 1151    0    9    0    0    0    0]\n",
      " [ 186   26    0  934    0    0    0  354    0]\n",
      " [ 357    0    8    0 1005    0    5    0  125]\n",
      " [  48    0    0    0    0 1438    0   14    0]\n",
      " [ 179    2    1    0    0    0 1307    0   11]\n",
      " [  72    2    0   42    0   23    0 1361    0]\n",
      " [ 216    0    2    0   77    0   62    0 1143]] \n",
      "\n",
      " [[825  21  17  13  11  52  19  30  12]\n",
      " [ 25 473   0   1   0   1   0   0   0]\n",
      " [109   0 389   0   2   0   0   0   0]\n",
      " [ 58  11   0 306   0   0   0 125   0]\n",
      " [137   0   3   0 318   0   1   0  41]\n",
      " [ 18   0   0   0   0 480   0   2   0]\n",
      " [ 76   0   0   0   0   0 423   0   1]\n",
      " [ 21   1   0   1   0   9   0 468   0]\n",
      " [ 96   0   0   0  10   0  19   0 375]]\n"
     ]
    }
   ],
   "source": [
    "PARAMS = {}\n",
    "PARAMS['pkl_name'] = './data/label8_eurusd_10bar_1500_500_val200_gaf_culr.pkl'\n",
    "PARAMS['classes'] = 9\n",
    "PARAMS['lr'] = 0.01\n",
    "PARAMS['epochs'] = 10\n",
    "PARAMS['batch_size'] = 64\n",
    "PARAMS['optimizer'] = optimizers.SGD(lr=PARAMS['lr'])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# load data & keras model\n",
    "data = load_pkl(PARAMS['pkl_name'])\n",
    "# train cnn model\n",
    "model, hist = train_model(PARAMS, data)\n",
    "# train & test result\n",
    "scores = model.evaluate(data['test_gaf'], data['test_label_arr'], verbose=0)\n",
    "print('CNN test accuracy:', scores[1])\n",
    "print_result(data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
